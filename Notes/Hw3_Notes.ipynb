{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Relevant Chapters for Homework 3**\n",
    "---\n",
    "### **Final Breakdown by Concept**\n",
    "| **Concept** | **Relevant Chapters** |\n",
    "|------------|----------------------|\n",
    "| Bayesian estimation for Poisson | 5.5.4, 7.2, 7.4.2, 8.2, 8.3 |\n",
    "| Credible sets (equitailed & HPD) | 8.7 |\n",
    "| MAP estimator | 7.2, 8.4 |\n",
    "| Bayesian hypothesis testing | 9.3, 9.8 |\n",
    "| Bayes factor & posterior odds | 8.8, 9.3 |\n",
    "| Pareto prior & posterior updates | 5.5.10, 8.3 |\n",
    "| Parameter transformations | 5.7 |\n",
    "| Jeffreys prior for Maxwell | 7.2, 8.3 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 \n",
    "\n",
    "Poisson,Pareto, Multinomial, Double Exponential, and Maxwell distributions. Also Transformations of Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Understanding Discrete Random Variables**\n",
    "\n",
    "Alright, imagine you have a bag of different-colored marbles. You reach into the bag, pull one out, and see its color. The color you get is **random**‚Äîyou can‚Äôt predict it exactly, but you know all the possible colors in the bag.\n",
    "\n",
    "---\n",
    "\n",
    "### **What is a Random Variable?**\n",
    "A **random variable** is just a fancy way of saying: ‚Äúsomething that can take different values, depending on chance.‚Äù \n",
    "\n",
    "Let‚Äôs call our random variable **X**. If X represents the color of a marble, it can be:\n",
    "- Red\n",
    "- Blue\n",
    "- Green\n",
    "- Yellow\n",
    "\n",
    "Each of these colors has a **probability**‚Äîa chance of happening. \n",
    "\n",
    "---\n",
    "\n",
    "### **What is a Discrete Random Variable?**\n",
    "A **discrete** random variable is one that can only take specific, separate values (not just any number). Think of rolling a die‚Äîit can land on **1, 2, 3, 4, 5, or 6**, but not something weird like 3.5.\n",
    "\n",
    "Examples of **discrete** random variables:\n",
    "- The number of marbles you pick (1, 2, 3, etc.).\n",
    "- How many heads you get when flipping a coin multiple times (0, 1, 2...).\n",
    "- The number of people in a room (can‚Äôt be 2.5 people!).\n",
    "\n",
    "---\n",
    "\n",
    "### **Probability Mass Function (PMF)**\n",
    "The **Probability Mass Function (PMF)** is just a way to organize all possible values and their probabilities. It tells us how likely each value is.\n",
    "\n",
    "Example: If we roll a 6-sided die, the PMF looks like this:\n",
    "\n",
    "| X (Number Rolled) | 1  | 2  | 3  | 4  | 5  | 6  |\n",
    "|------------------|----|----|----|----|----|----|\n",
    "| P(X) (Probability) | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 |\n",
    "\n",
    "Since it‚Äôs a fair die, each number has an equal chance of **1/6**.\n",
    "\n",
    "Important Rule: The sum of all probabilities **must** add up to 1 (because one of these numbers **has to** happen).\n",
    "\n",
    "---\n",
    "\n",
    "### **Cumulative Distribution Function (CDF)**\n",
    "The **Cumulative Distribution Function (CDF)** is like keeping track of **everything that has happened so far**. Instead of looking at just one number, it tells you the probability that the number you roll is **less than or equal to** some value.\n",
    "\n",
    "For the same die example:\n",
    "\n",
    "| X ‚â§ Number | Probability (CDF) |\n",
    "|------------|------------------|\n",
    "| ‚â§ 1 | 1/6 = 0.1667 |\n",
    "| ‚â§ 2 | 2/6 = 0.3333 |\n",
    "| ‚â§ 3 | 3/6 = 0.5000 |\n",
    "| ‚â§ 4 | 4/6 = 0.6667 |\n",
    "| ‚â§ 5 | 5/6 = 0.8333 |\n",
    "| ‚â§ 6 | 6/6 = 1.0000 |\n",
    "\n",
    "So if you ask, ‚ÄúWhat‚Äôs the chance of rolling a 3 or lower?‚Äù The answer is **0.5 (or 50%)**, because half of the die‚Äôs outcomes are 3 or less.\n",
    "\n",
    "---\n",
    "\n",
    "### **Expectation (Mean)**\n",
    "The **Expectation (E[X])**, also called the **mean**, is like the ‚Äúbalance point‚Äù of the random variable. It‚Äôs what you‚Äôd expect **on average** if you did the experiment a lot of times.\n",
    "\n",
    "For a discrete random variable, the expectation is:\n",
    "\n",
    "$$\n",
    "E[X] = x_1p_1 + x_2p_2 + ... + x_n p_n\n",
    "$$\n",
    "\n",
    "It‚Äôs a **weighted average** where the probabilities are the weights.\n",
    "\n",
    "Example: Suppose you have a game where:\n",
    "- You win **$1** with probability **0.5**\n",
    "- You win **$3** with probability **0.3**\n",
    "- You win **$5** with probability **0.2**\n",
    "\n",
    "Then the expected winnings are:\n",
    "\n",
    "$$\n",
    "E[X] = (1 \\times 0.5) + (3 \\times 0.3) + (5 \\times 0.2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 0.5 + 0.9 + 1.0 = 2.4\n",
    "$$\n",
    "\n",
    "So, **on average**, you‚Äôd expect to win **$2.40** per game.\n",
    "\n",
    "---\n",
    "\n",
    "### **Variance and Standard Deviation (How Much It Varies)**\n",
    "The **Variance** tells us how much the values **spread out** from the mean.\n",
    "\n",
    "$$\n",
    "Var(X) = \\sum (x_n - E[X])^2 p_n\n",
    "$$\n",
    "\n",
    "The **standard deviation** is just the square root of the variance. It helps us understand how much the values deviate from the average.\n",
    "\n",
    "A small variance means the values are **close together** (not much randomness).\n",
    "A large variance means the values are **spread out** (more randomness).\n",
    "\n",
    "---\n",
    "\n",
    "### **Higher Moments: Skewness & Kurtosis**\n",
    "- **Skewness (Œ≥)** tells us if the distribution leans more **to the left or right**.\n",
    "  - If skewness is **0**, the data is **perfectly symmetrical**.\n",
    "  - If skewness is **positive**, the data is **skewed right** (longer tail on the right).\n",
    "  - If skewness is **negative**, the data is **skewed left** (longer tail on the left).\n",
    "\n",
    "- **Kurtosis (Œ∫)** tells us **how peaked or flat** the distribution is.\n",
    "  - High kurtosis = **Tall & skinny** (more extreme values).\n",
    "  - Low kurtosis = **Flat & wide** (values more spread out).\n",
    "\n",
    "---\n",
    "\n",
    "### **Moment-Generating Function (MGF)**\n",
    "This one is a bit trickier! The **Moment-Generating Function (MGF)** helps us find different moments (mean, variance, etc.) using derivatives. You probably won‚Äôt need to use it directly unless you‚Äôre working with **advanced probability**.\n",
    "\n",
    "It‚Äôs like a magical function that, when you take its derivatives, gives you different moments of the distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### **Entropy (How Uncertain It Is)**\n",
    "Entropy measures **how much randomness or uncertainty** there is. \n",
    "\n",
    "Formula:\n",
    "\n",
    "$$\n",
    "H(X) = -\\sum p_i \\log(p_i)\n",
    "$$\n",
    "\n",
    "- If all probabilities are **equal**, entropy is **high** (maximum randomness).\n",
    "- If one outcome is **certain** (like rolling a loaded die that always lands on 6), entropy is **low** (less randomness).\n",
    "\n",
    "---\n",
    "\n",
    "### **Joint Distributions (When You Have Two Variables)**\n",
    "What if you have two random variables, **X** and **Y**, that are connected? \n",
    "\n",
    "For example, suppose:\n",
    "- **X = number of candies you get**\n",
    "- **Y = number of chocolates you get**\n",
    "\n",
    "The **joint probability** of getting X candies and Y chocolates at the same time is written as:\n",
    "\n",
    "$$\n",
    "P(X = x, Y = y)\n",
    "$$\n",
    "\n",
    "If X and Y are **independent**, it means knowing X tells you **nothing** about Y, so:\n",
    "\n",
    "$$\n",
    "P(X = x, Y = y) = P(X = x) P(Y = y)\n",
    "$$\n",
    "\n",
    "But if they‚Äôre **not independent**, then knowing one affects the other.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Recap**\n",
    "1. **Discrete random variables** take countable values (like dice rolls, number of kids in a family).\n",
    "2. **PMF** tells us the probability of each value.\n",
    "3. **CDF** tells us the probability of getting **less than or equal to** a value.\n",
    "4. **Expectation (Mean)** is the average outcome over many trials.\n",
    "5. **Variance & Standard Deviation** tell us how much the values spread out.\n",
    "6. **Skewness & Kurtosis** describe the shape of the distribution.\n",
    "7. **Entropy** measures uncertainty.\n",
    "8. **Joint Distributions** deal with multiple variables at once.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Standard Discrete Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's go on a journey where we explore different **types** of random events. Think of these like different kinds of games or situations where randomness plays a role.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Discrete Uniform Distribution (The Fair Game)**\n",
    "Imagine you have a **fair spinner** with **n** equal sections, labeled **1 to n**. If you spin it, every number has the **same chance** of appearing.\n",
    "\n",
    "For example, if your spinner has **5** sections numbered **1, 2, 3, 4, and 5**, each number has a **1/5 = 0.2** probability of being chosen.\n",
    "\n",
    "| Number (X) | 1 | 2 | 3 | 4 | 5 |\n",
    "|------------|----|----|----|----|----|\n",
    "| Probability (P(X)) | 0.2 | 0.2 | 0.2 | 0.2 | 0.2 |\n",
    "\n",
    "This is called the **Discrete Uniform Distribution** because all outcomes are **equally likely**.\n",
    "\n",
    "üìå **Expectation (Mean) & Variance**\n",
    "- The **average outcome** (Expectation \\(E[X]\\)) is:\n",
    "\n",
    "  $$\n",
    "  E[X] = \\frac{n+1}{2}\n",
    "  $$\n",
    "\n",
    "  For example, for a spinner with numbers **1 to 5**:\n",
    "\n",
    "  $$\n",
    "  E[X] = \\frac{5+1}{2} = 3\n",
    "  $$\n",
    "\n",
    "- The **variance** (how spread out the numbers are) is:\n",
    "\n",
    "  $$\n",
    "  Var(X) = \\frac{n^2 - 1}{12}\n",
    "  $$\n",
    "\n",
    "üìå **Why is this useful?**\n",
    "- It's great for **random sampling**, like picking lottery numbers or selecting a random person from a group.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Bernoulli Distribution (A Coin Flip)**\n",
    "Now, imagine flipping a **coin**. It can land on:\n",
    "- **Heads (1) ‚Üí Success**\n",
    "- **Tails (0) ‚Üí Failure**\n",
    "\n",
    "If the probability of getting heads is **p**, and the probability of getting tails is **1 - p**, this is called a **Bernoulli Distribution**.\n",
    "\n",
    "| Outcome (Y) | 0 (Tails) | 1 (Heads) |\n",
    "|------------|----------|----------|\n",
    "| Probability | \\(1 - p\\) | \\(p\\) |\n",
    "\n",
    "üìå **Expectation & Variance**\n",
    "- The **mean** (expected value) is:\n",
    "\n",
    "  $$\n",
    "  E[Y] = p\n",
    "  $$\n",
    "\n",
    "- The **variance** (spread of outcomes) is:\n",
    "\n",
    "  $$\n",
    "  Var(Y) = p(1 - p)\n",
    "  $$\n",
    "\n",
    "üìå **Why is this useful?**\n",
    "- It models **yes/no** situations: \n",
    "  - Will it rain today? (yes or no)\n",
    "  - Will a machine fail? (yes or no)\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Binomial Distribution (A Series of Coin Flips)**\n",
    "Imagine flipping **n** coins (or repeating the same event **n** times). Instead of looking at just one flip, we count how many times we get **heads** (successes).\n",
    "\n",
    "If:\n",
    "- Each flip has probability **p** of success (getting heads)\n",
    "- There are **n** flips\n",
    "- The flips are **independent** (one flip doesn‚Äôt affect another)\n",
    "\n",
    "Then, the number of successes follows a **Binomial Distribution**.\n",
    "\n",
    "### **Example: Left-Handed Families**\n",
    "Suppose **10** families each have a child, and we know that **26%** of children born to left-handed parents are also left-handed. Let‚Äôs find the probability that exactly **3 out of 10** children are left-handed.\n",
    "\n",
    "We use the **Binomial formula**:\n",
    "\n",
    "$$\n",
    "P(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x}\n",
    "$$\n",
    "\n",
    "For **X = 3**, **n = 10**, and **p = 0.26**:\n",
    "\n",
    "$$\n",
    "P(X = 3) = \\binom{10}{3} (0.26)^3 (0.74)^7\n",
    "$$\n",
    "\n",
    "üìå **Expectation & Variance**\n",
    "- The expected number of successes:\n",
    "\n",
    "  $$\n",
    "  E[X] = np\n",
    "  $$\n",
    "\n",
    "- The variance:\n",
    "\n",
    "  $$\n",
    "  Var(X) = np(1 - p)\n",
    "  $$\n",
    "\n",
    "üìå **Why is this useful?**\n",
    "- It models things like:\n",
    "  - Number of **students passing an exam** (each has a probability of passing).\n",
    "  - Number of **defective products in a batch** (each product has a failure probability).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Hypergeometric Distribution (Picking Marbles Without Replacement)**\n",
    "Imagine you have **a bag of marbles** with:\n",
    "- **k white** marbles\n",
    "- **m - k black** marbles\n",
    "- You pick **n** marbles **without putting them back**.\n",
    "\n",
    "The number of white marbles you get follows a **Hypergeometric Distribution**.\n",
    "\n",
    "### **Example: Drawing Balls from a Box**\n",
    "Suppose a box contains **40 balls**, **15 are white**, and **25 are black**. You **randomly select 10 balls** without replacement. What‚Äôs the probability that **at least 2** are white?\n",
    "\n",
    "We use the **Hypergeometric formula**:\n",
    "\n",
    "$$\n",
    "P(X = x) = \\frac{\\binom{k}{x} \\binom{m-k}{n-x}}{\\binom{m}{n}}\n",
    "$$\n",
    "\n",
    "üìå **Expectation & Variance**\n",
    "- The expected number of white balls:\n",
    "\n",
    "  $$\n",
    "  E[X] = n \\frac{k}{m}\n",
    "  $$\n",
    "\n",
    "- The variance:\n",
    "\n",
    "  $$\n",
    "  Var(X) = n \\frac{k}{m} \\left(1 - \\frac{k}{m} \\right) \\frac{m-n}{m-1}\n",
    "  $$\n",
    "\n",
    "üìå **Why is this useful?**\n",
    "- It models **real-world problems** where you **don‚Äôt replace items**, like:\n",
    "  - Selecting a **random jury** from a group.\n",
    "  - Checking **defective products** in a batch.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Recap**\n",
    "| **Distribution** | **What It Models** | **Mean \\(E[X]\\)** | **Variance \\(Var(X)\\)** |\n",
    "|-----------------|-------------------|-----------------|----------------|\n",
    "| **Discrete Uniform** | Equal chance of picking numbers | \\(\\frac{n+1}{2}\\) | \\(\\frac{n^2 - 1}{12}\\) |\n",
    "| **Bernoulli** | Single yes/no outcome (coin flip) | \\(p\\) | \\(p(1 - p)\\) |\n",
    "| **Binomial** | Multiple yes/no outcomes (multiple coin flips) | \\(np\\) | \\(np(1 - p)\\) |\n",
    "| **Hypergeometric** | Drawing without replacement | \\(n \\frac{k}{m}\\) | \\(n \\frac{k}{m} \\left(1 - \\frac{k}{m} \\right) \\frac{m-n}{m-1}\\) |\n",
    "\n",
    "---\n",
    "\n",
    "üé≤ **Key Takeaways:**\n",
    "1. **Uniform Distribution** ‚Üí Everything is equally likely (like rolling a fair die).\n",
    "2. **Bernoulli Distribution** ‚Üí One single event with two possible outcomes (like a coin flip).\n",
    "3. **Binomial Distribution** ‚Üí A series of **independent** yes/no trials (like flipping multiple coins).\n",
    "4. **Hypergeometric Distribution** ‚Üí Selecting items **without replacement** (like drawing cards from a deck)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 P"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
